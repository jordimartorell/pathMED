% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trainModel.R
\name{trainModel}
\alias{trainModel}
\title{Train ML models and perform internal validation}
\usage{
trainModel(
  inputData,
  metadata,
  models = methodsML(outcomeClass = "character"),
  var2predict,
  positiveClass = NULL,
  pairingColumn = NULL,
  Koutter = 5,
  Kinner = 4,
  repeatsCV = 5,
  filterFeatures = NULL,
  filterSizes = seq(2, 100, by = 2),
  rerank = FALSE,
  continue_on_fail = TRUE,
  saveLogFile = NULL
)
}
\arguments{
\item{inputData}{Feature matrix. Samples in columns and features in
rows. inputData must be a numerical matrix}

\item{metadata}{dataframe with information for each sample. Samples in rows
and variables in columns}

\item{models}{named list with the ML models generated with
caret::caretModelSpec function. methodsML function may be used to prepare
this list.}

\item{var2predict}{character with the column name of the @metadata to predict}

\item{positiveClass}{value that must be considered as positive
class (only for categoric variables). If NULL, the last class by
alphabetical order is considered as the positive class.}

\item{pairingColumn}{Optional. Character with the column name of the
@metadata with pairing information (e.g. technical replicates). Paired
samples will always be assigned to the same set (training/test) to avoid
data leakage.}

\item{Koutter}{number of outter cross-validation folds.
A list of integer with elements for each resampling iteration is admitted.
Each list element is a vector of integers corresponding to the rows used for
training on that iteration.}

\item{Kinner}{number of innter cross-validation folds (for parameter tuning).}

\item{repeatsCV}{number of repetitions of the parameter tuning process.}

\item{filterFeatures}{"rfe" (Recursive Feature Elimination), "sbf" (Selection
By Filtering) or NULL (no feature selection).}

\item{filterSizes}{Only for filterFeatures = "rfe". A numeric vector of
integers corresponding to the number of features that should be retained.}

\item{rerank}{Only for filterFeatures = "rfe". A logical indicating if the
variable importance must be re-calculated each time features are removed.}

\item{continue_on_fail}{whether or not to continue training the models if any
of them fail.}

\item{saveLogFile}{path to a .txt file in which to save error and warning
messages.}
}
\value{
A list with four elements. The first one is the model. The second one
is a table with different metrics obtained. The third one is a list with the
best parameters selected in tuning process. The last element contains data
for AUC plots
}
\description{
Train ML models and perform internal validation
}
\examples{
data(exampleData, exampleMetadata)
\donttest{

scoresExample <- getScores(exampleData, geneSets="tmod", method="GSVA")

trainedModel <- trainModel(inputData=scoresExample,
metadata=exampleMetadata,
var2predict="Response",
models=methodsML("svmLinear"))
}

}
\references{
Toro-Domínguez, D. et al (2022). \emph{Scoring personalized
molecular portraits identify Systemic Lupus Erythematosus subtypes and
predict individualized drug responses, symptomatology and
disease progression}
 . Briefings in Bioinformatics. 23(5)
}
\author{
Jordi Martorell-Marugán, \email{jordi.martorell@genyo.es}

Daniel Toro-Dominguez, \email{danieltorodominguez@gmail.com}
}
